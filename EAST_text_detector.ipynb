{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EAST_dataset",
      "provenance": [],
      "collapsed_sections": [
        "QYP_yAGvd05H",
        "T874dqy_dyjf"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/EAST/blob/master/EAST_text_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyapm5xLqREO",
        "colab_type": "text"
      },
      "source": [
        "##1. Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2dp5i49ZJGr",
        "colab_type": "text"
      },
      "source": [
        "[**Tasks - Incidental Scene Text**](https://rrc.cvc.uab.es/?ch=4&com=tasks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6n5wRjEg_RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.model_zoo import load_url\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAmisDeYpzym",
        "colab_type": "code",
        "outputId": "2d5c56f0-d28f-4352-eba7-5142459bf440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "!git clone -l -s git://github.com/kavyajeetbora/EAST.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo/cloned-repo\n",
            "cloned-repo\t     dataset.py\t\t EAST_text_detector.ipynb  model.py\n",
            "dataset_original.py  EAST_dataset.ipynb  loss.py\t\t   train.py\n",
            "CPU times: user 118 ms, sys: 27.3 ms, total: 145 ms\n",
            "Wall time: 7.25 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98XW9aIixCjd",
        "colab_type": "code",
        "outputId": "8c0cc3af-100c-487e-ce3a-9c74ab004e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnP26VecZ4by",
        "colab_type": "code",
        "outputId": "b197c406-6514-4915-c481-68a76875506a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from dataset_original import custom_dataset\n",
        "\n",
        "# AI4Bharat dataset\n",
        "image_address = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/Simple YOLO model/Data/Sample Images'\n",
        "label_address = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/Simple YOLO model/Data/Sample Annotations'\n",
        "\n",
        "\n",
        "# icdar dataset\n",
        "# image_address = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/EAST scene text detector/data/ICDAR dataset/Images'\n",
        "# label_address = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/EAST scene text detector/data/ICDAR dataset/Labels'\n",
        "\n",
        "training_dataset = custom_dataset(image_address, label_address)\n",
        "print(len(training_dataset))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQbQcRblaZWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_vertices(lines):\n",
        "\t'''extract vertices info from txt lines\n",
        "\tInput:\n",
        "\t\tlines   : list of string info\n",
        "\tOutput:\n",
        "\t\tvertices: vertices of text regions <numpy.ndarray, (n,8)>\n",
        "\t\tlabels  : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
        "\t'''\n",
        "\tlabels = []\n",
        "\tvertices = []\n",
        "\tfor line in lines:\n",
        "\t\tvertices.append(list(map(int,line.rstrip('\\n').lstrip('\\ufeff').split(',')[:8])))\n",
        "\t\tlabel = 0 if '##::' in line else 1\n",
        "\t\tlabels.append(label)\n",
        "\treturn np.array(vertices), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Fmu_OcbvdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset_original import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjUXNkFjbhYC",
        "colab_type": "code",
        "outputId": "3f266ec1-d27b-48e1-f7d4-b1cc25c73655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "img = Image.open(image_address+'/0.jpg')\n",
        "\n",
        "with open(label_address+'/0.txt', 'r') as f:\n",
        "\t\t\tlines = f.readlines()\n",
        "vertices, labels = extract_vertices(lines)\n",
        "\n",
        "img, vertices = adjust_height(img, vertices) \n",
        "img, vertices = rotate_img(img, vertices)\n",
        "img, vertices = crop_img(img, vertices, labels, 512)\n",
        "\n",
        "for vertice in vertices:\n",
        "  print(vertice)\n",
        "  print('-'*20)\n",
        "  \n",
        "print(labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-27.95817481 259.01735746 209.1379291  118.39098975  88.1314165\n",
            " 192.74665186 166.12367056 261.62996655]\n",
            "--------------------\n",
            "[154.5562676  465.84930483 401.137368   329.08821645  94.45545883\n",
            " 201.18173565 171.04379279 279.90704907]\n",
            "--------------------\n",
            "[351.11417886 609.4106503  510.58394653 520.463317    95.68495589\n",
            " 201.35733311 176.83923111 274.45818969]\n",
            "--------------------\n",
            "[1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Be5YdfbbSCs",
        "colab_type": "code",
        "outputId": "17ac1a17-5695-47c7-c952-7d14759d815e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score_map, geo_map, ignored_map = get_score_geo(img, vertices, labels, 0.25, 512)\n",
        "\n",
        "torch.sum(score_map)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(814.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsangoljUZ6v",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmbW10gwUTRX",
        "colab_type": "code",
        "outputId": "f57b0166-5160-49da-f4a9-e1c10fc873f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "%%time\n",
        "train_loader = DataLoader(training_dataset, shuffle = True, batch_size=8)\n",
        "\n",
        "imgs, gt_score, gt_geo, ignored_maps = next(iter(train_loader))\n",
        "\n",
        "print(imgs.size(), gt_score.size(), gt_geo.size(), ignored_maps.size())\n",
        "\n",
        "print(torch.sum(gt_score))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 512, 512]) torch.Size([8, 1, 128, 128]) torch.Size([8, 5, 128, 128]) torch.Size([8, 1, 128, 128])\n",
            "tensor(6123.)\n",
            "CPU times: user 4.65 s, sys: 3.6 s, total: 8.25 s\n",
            "Wall time: 4.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Ao3H-fU45B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import EAST\n",
        "\n",
        "model = EAST()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVd09gNmU_gE",
        "colab_type": "code",
        "outputId": "ea98209c-ab17-444f-a787-0ad8a0ab316d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_score, pred_geo = model(imgs)\n",
        "\n",
        "print(pred_score.size(), pred_geo.size())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 128, 128]) torch.Size([8, 5, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwKLUhtVIt9",
        "colab_type": "code",
        "outputId": "ec1c3ace-c7cf-4fdc-fc7e-9cb310387561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from loss import Loss\n",
        "\n",
        "loss_fn = Loss()\n",
        "\n",
        "loss_fn(gt_score, pred_score, gt_geo, pred_geo, ignored_maps)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classify loss is 0.94193238, angle loss is 0.83617729, iou loss is 1.76681161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.0705, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03aAZoSGXTLf",
        "colab_type": "text"
      },
      "source": [
        "## Training Full Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBnoLsZyXpzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e85c3d7a-8306-43dc-b918-887d9cd966b9"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I64GQ2hjXxuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5//2], gamma=0.1)\n",
        "criterion = Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeIQGzb6XVa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "def train(train_img_path, train_gt_path, pths_path, batch_size, lr, num_workers, epoch_iter, interval):\n",
        "    file_num = len(os.listdir(train_img_path))\n",
        "    print(file_num)\n",
        "    trainset = custom_dataset(train_img_path, train_gt_path)\n",
        "    train_loader = data.DataLoader(trainset, batch_size=batch_size, \\\n",
        "                                   shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "\t\n",
        "    criterion = Loss()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = EAST()\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[epoch_iter//2], gamma=0.1)\n",
        "  \n",
        "    for epoch in range(epoch_iter):\n",
        "      model.train()\n",
        "      scheduler.step()\n",
        "      epoch_loss = 0\n",
        "      epoch_time = time.time()\n",
        "      for i, (img, gt_score, gt_geo, ignored_map) in enumerate(train_loader):\n",
        "        start_time = time.time()\n",
        "        img, gt_score, gt_geo, ignored_map = img.to(device), gt_score.to(device), gt_geo.to(device), ignored_map.to(device)\n",
        "        pred_score, pred_geo = model(img)\n",
        "        loss = criterion(gt_score, pred_score, gt_geo, pred_geo, ignored_map)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch is [{}/{}], mini-batch is [{}/{}], time consumption is {:.8f}, batch_loss is {:.8f}'.format(\\\n",
        "                  epoch+1, epoch_iter, i+1, int(file_num/batch_size), time.time()-start_time, loss.item()))\n",
        "        \n",
        "      print('epoch_loss is {:.8f}, epoch_time is {:.8f}'.format(epoch_loss/int(file_num/batch_size), time.time()-epoch_time))\n",
        "      print(time.asctime(time.localtime(time.time())))\n",
        "      print('='*50)\n",
        "      if (epoch + 1) % interval == 0:\n",
        "        state_dict = model.module.state_dict() if data_parallel else model.state_dict()\n",
        "        torch.save(state_dict, os.path.join(pths_path, 'model_epoch_{}.pth'.format(epoch+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxuHC3Wybb7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "69599094-7a44-4da9-88ba-b8aebb66611d"
      },
      "source": [
        "training = train(image_address, label_address, 'models', batch_size=4, lr=1e-3, num_workers=0, epoch_iter=1, interval=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "classify loss is 0.92798018, angle loss is 0.80903655, iou loss is 2.18565321\n",
            "Epoch is [1/1], mini-batch is [1/107], time consumption is 0.63570571, batch_loss is 11.20399857\n",
            "classify loss is 0.85519922, angle loss is 0.60309690, iou loss is 1.61759293\n",
            "Epoch is [1/1], mini-batch is [2/107], time consumption is 0.51502895, batch_loss is 8.50376129\n",
            "classify loss is 0.90211928, angle loss is 0.86482328, iou loss is 1.91286838\n",
            "Epoch is [1/1], mini-batch is [3/107], time consumption is 0.55839729, batch_loss is 11.46322060\n",
            "classify loss is 0.89295387, angle loss is 0.77143377, iou loss is 1.83569467\n",
            "Epoch is [1/1], mini-batch is [4/107], time consumption is 0.59625363, batch_loss is 10.44298649\n",
            "classify loss is 0.90469599, angle loss is 0.78680545, iou loss is 1.74911380\n",
            "Epoch is [1/1], mini-batch is [5/107], time consumption is 0.55348015, batch_loss is 10.52186394\n",
            "classify loss is 0.90775156, angle loss is 0.88408160, iou loss is 1.75043941\n",
            "Epoch is [1/1], mini-batch is [6/107], time consumption is 0.52891755, batch_loss is 11.49900818\n",
            "classify loss is 0.85956734, angle loss is 0.76944536, iou loss is 1.53295195\n",
            "Epoch is [1/1], mini-batch is [7/107], time consumption is 0.54800701, batch_loss is 10.08697319\n",
            "classify loss is 0.92101860, angle loss is 0.69813353, iou loss is 1.57643914\n",
            "Epoch is [1/1], mini-batch is [8/107], time consumption is 0.53000808, batch_loss is 9.47879314\n",
            "classify loss is 0.88649464, angle loss is 0.78825295, iou loss is 1.70535839\n",
            "Epoch is [1/1], mini-batch is [9/107], time consumption is 0.56234527, batch_loss is 10.47438240\n",
            "classify loss is 0.92678678, angle loss is 0.67310250, iou loss is 1.82130039\n",
            "Epoch is [1/1], mini-batch is [10/107], time consumption is 0.54209590, batch_loss is 9.47911167\n",
            "classify loss is 0.91813791, angle loss is 0.88920230, iou loss is 1.64203918\n",
            "Epoch is [1/1], mini-batch is [11/107], time consumption is 0.55649400, batch_loss is 11.45219994\n",
            "classify loss is 0.88118100, angle loss is 0.81243795, iou loss is 1.44734478\n",
            "Epoch is [1/1], mini-batch is [12/107], time consumption is 0.53831267, batch_loss is 10.45290470\n",
            "classify loss is 0.83733034, angle loss is 0.64732289, iou loss is 1.35816491\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}